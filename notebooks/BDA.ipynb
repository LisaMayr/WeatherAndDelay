{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80d4f5ae-55f7-4f66-8ca5-9e5899772ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.31.0)\n",
      "Collecting pymongo\n",
      "  Downloading pymongo-4.16.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2023.7.22)\n",
      "Collecting dnspython<3.0.0,>=2.6.1 (from pymongo)\n",
      "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Downloading pymongo-4.16.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m159.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m181.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
      "Successfully installed dnspython-2.8.0 pymongo-4.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install requests pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3be54b07-d120-480b-8cd5-301fa323d746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216.58.204.142\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "print(socket.gethostbyname('google.com'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b2d4bb1-284d-473b-8cc4-8fcdbf5b267f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erfolg! Daten geladen.\n",
      "Zeit: 2024-01-01T00:00+00:00 -> Tempe: None°C\n",
      "Zeit: 2024-01-01T00:10+00:00 -> Tempe: None°C\n",
      "Zeit: 2024-01-01T00:20+00:00 -> Tempe: None°C\n",
      "Zeit: 2024-01-01T00:30+00:00 -> Tempe: None°C\n",
      "Zeit: 2024-01-01T00:40+00:00 -> Tempe: None°C\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Wir nutzen den TAWES-Endpunkt, der für Station 11035 meist offen ist\n",
    "url = \"https://dataset.api.hub.geosphere.at/v1/station/historical/tawes-v1-10min\"\n",
    "\n",
    "params = {\n",
    "    \"parameters\": \"TL\",         # Lufttemperatur (10-Minuten-Takt)\n",
    "    \"station_ids\": \"11035\",     # Wien Hohe Warte\n",
    "    \"start\": \"2024-01-01T00:00\",\n",
    "    \"end\": \"2024-01-10T02:00\",  # Zeitraum zum Testen kurz halten\n",
    "    \"format\": \"geojson\"         # GeoJSON ist das Standard-Datenformat der API\n",
    "} \n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(\"Erfolg! Daten geladen.\")\n",
    "    # Zeige die ersten paar Zeitstempel und Werte\n",
    "    timestamps = data.get(\"timestamps\", [])\n",
    "    values = data[\"features\"][0][\"properties\"][\"parameters\"][\"TL\"][\"data\"]\n",
    "    for ts, val in zip(timestamps[:5], values[:5]):\n",
    "        print(f\"Zeit: {ts} -> Tempe: {val}°C\")\n",
    "else:\n",
    "    print(f\"Fehler: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "098b1e04-bdf7-40c2-b091-06b60cfcd2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rufe Wiener Linien Echtzeitdaten ab...\n",
      "Haltestelle: Schönbrunn\n",
      "Linie U4 Richtung HÜTTELDORF        in 3 Minuten.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Echtzeit-Monitor Endpunkt\n",
    "url = \"https://www.wienerlinien.at/ogd_realtime/monitor\"\n",
    "\n",
    "params = {\n",
    "    \"rbl\": \"4426\", # Stephansplatz U3\n",
    "    \"activateTrafficInfo\": \"true\"\n",
    "}\n",
    "\n",
    "print(\"Rufe Wiener Linien Echtzeitdaten ab...\")\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    monitors = data[\"data\"][\"monitors\"]\n",
    "    print(f\"Haltestelle: {monitors[0]['locationStop']['properties']['title']}\")\n",
    "    \n",
    "    for line in monitors[0][\"lines\"]:\n",
    "        departure = line[\"departures\"][\"departure\"][0][\"departureTime\"][\"countdown\"]\n",
    "        print(f\"Linie {line['name']} Richtung {line['towards']} in {departure} Minuten.\")\n",
    "else:\n",
    "    print(f\"Fehler: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9af5a3ef-6581-4c5d-a1ef-5c0e67b1fcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erfolg! Hier sind die Rohdaten:\n",
      "\n",
      "{\"media_type\":\"application/json\",\"type\":\"FeatureCollection\",\"version\":\"v1\",\"timestamps\":[\"2023-05-01T00:00+00:00\",\"2023-05-01T00:10+00:00\",\"2023-05-01T00:20+00:00\",\"2023-05-01T00:30+00:00\",\"2023-05-01T00:40+00:00\",\"2023-05-01T00:50+00:00\",\"2023-05-01T01:00+00:00\",\"2023-05-01T01:10+00:00\",\"2023-05-01T01:20+00:00\",\"2023-05-01T01:30+00:00\",\"2023-05-01T01:40+00:00\",\"2023-05-01T01:50+00:00\",\"2023-05-01T02:00+00:00\",\"2023-05-01T02:10+00:00\",\"2023-05-01T02:20+00:00\",\"2023-05-01T02:30+00:00\",\"2023-05-01T02:40+00:00\",\"2023-05-01T02:50+00:00\",\"2023-05-01T03:00+00:00\",\"2023-05-01T03:10+00:00\",\"2023-05-01T03:20+00:00\",\"2023-05-01T03:30+00:00\",\"2023-05-01T03:40+00:00\",\"2023-05-01T03:50+00:00\",\"2023-05-01T04:00+00:00\",\"2023-05-01T04:10+00:00\",\"2023-05-01T04:20+00:00\",\"2023-05-01T04:30+00:00\",\"2023-05-01T04:40+00:00\",\"2023-05-01T04:50+00:00\",\"2023-05-01T05:00+00:00\"],\"features\":[{\"type\":\"Feature\",\"geometry\":{\"type\":\"Point\",\"coordinates\":[16.35638888888889,48.24861111111111]},\"properties\":{\"parameters\":{\"TL\":{\"name\":\"Lufttemperatur\",\"unit\":\"°C\",\"data\":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null]}},\"station\":\"11035\"}}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import io\n",
    "import pandas as pd # Falls installiert, ansonsten nutzen wir csv Modul\n",
    "\n",
    "url = \"https://dataset.api.hub.geosphere.at/v1/station/historical/tawes-v1-10min\"\n",
    "\n",
    "# Wir wählen einen Zeitraum, der garantiert existiert (z.B. Frühling 2023)\n",
    "params = {\n",
    "    \"parameters\": \"TL\",\n",
    "    \"station_ids\": \"11035\",\n",
    "    \"start\": \"2023-05-01T00:00\",\n",
    "    \"end\": \"2023-05-01T05:00\",\n",
    "    \"format\": \"csv\" # CSV ist robuster für historische Daten\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    if response.text.strip() == \"\":\n",
    "        print(\"Die API hat eine leere Datei geliefert. Versuche einen anderen Zeitraum.\")\n",
    "    else:\n",
    "        print(\"Erfolg! Hier sind die Rohdaten:\\n\")\n",
    "        print(response.text)\n",
    "        \n",
    "        # Optional: Direkt in ein Pandas DataFrame laden für die Analyse\n",
    "        # df = pd.read_csv(io.StringIO(response.text))\n",
    "        # print(df.head())\n",
    "else:\n",
    "    print(f\"Fehler: {response.status_code}\")\n",
    "    print(\"Meldung:\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7784426-1a97-4a33-933e-978ef709bdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sende Anfrage an GeoSphere API...\n",
      "ERFOLG: Daten empfangen!\n",
      "Anzahl der Zeitstempel: 1297\n",
      "Erste gemessene Temperatur: 6.5°C\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Die Basis-URL (Endpunkt)\n",
    "base_url = \"https://dataset.api.hub.geosphere.at/v1/station/historical/klima-v1-10min\"\n",
    "\n",
    "# Die Parameter als Dictionary (Übersichtlicher und leichter zu ändern)\n",
    "params = {\n",
    "    \"parameters\": [\"RR\", \"TL\"],      # Niederschlag (RR) und Temperatur (TL)\n",
    "    \"start\": \"2024-01-01T00:00\",\n",
    "    \"end\": \"2024-01-10T00:00\",\n",
    "    \"station_ids\": \"5882\",           # Die gewünschte Stations-ID\n",
    "    \"output_format\": \"geojson\"       # Das funktionierende Format\n",
    "}\n",
    "\n",
    "print(\"Sende Anfrage an GeoSphere API...\")\n",
    "\n",
    "try:\n",
    "    # Der API-Call\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Prüfen, ob die Anfrage erfolgreich war (Status 200)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(\"ERFOLG: Daten empfangen!\")\n",
    "        \n",
    "        # Kurze Analyse der Struktur\n",
    "        if \"features\" in data and len(data[\"features\"]) > 0:\n",
    "            count = len(data.get(\"timestamps\", []))\n",
    "            print(f\"Anzahl der Zeitstempel: {count}\")\n",
    "            \n",
    "            # Beispiel: Ersten Temperaturwert anzeigen\n",
    "            first_temp = data[\"features\"][0][\"properties\"][\"parameters\"][\"TL\"][\"data\"][0]\n",
    "            print(f\"Erste gemessene Temperatur: {first_temp}°C\")\n",
    "\n",
    "        \n",
    "        else:\n",
    "            print(\"Verbindung ok, aber keine Daten im 'features' Feld gefunden.\")\n",
    "            \n",
    "    elif response.status_code == 403:\n",
    "        print(\"Fehler 403: Zugriff verweigert. Prüfe Stations-ID oder Parameter.\")\n",
    "    else:\n",
    "        print(f\"Fehler {response.status_code}: {response.text}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ein Fehler ist aufgetreten: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "82066bc1-4918-4414-830c-906e1930e75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sende Anfrage an GeoSphere API...\n",
      "ERFOLG: Daten empfangen!\n",
      "Erster gemessener Temperaturwert: 6.5°C\n",
      "Frame erstellt. 145 Datensätze bereit für MongoDB.\n",
      "\n",
      "Beispiel-Datensatz für MongoDB:\n",
      "{\n",
      "  \"timestamp\": \"2024-01-01T00:00+00:00\",\n",
      "  \"RR\": 0.0,\n",
      "  \"TL\": 6.5,\n",
      "  \"P\": 983.8,\n",
      "  \"FF\": 1.5,\n",
      "  \"SO\": 0.0,\n",
      "  \"RF\": 71.0,\n",
      "  \"station_id\": \"5882\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Die Basis-URL (Klima-Endpunkt)\n",
    "base_url = \"https://dataset.api.hub.geosphere.at/v1/station/historical/klima-v1-10min\"\n",
    "\n",
    "# Alle deine gewünschten Parameter\n",
    "params = {\n",
    "    \"parameters\": [\"RR\", \"TL\", \"P\", \"FF\", \"SO\", \"RF\"],\n",
    "    \"start\": \"2024-01-01T00:00\",\n",
    "    \"end\": \"2024-01-02T00:00\", # Zeitraum kurz für den Test\n",
    "    \"station_ids\": \"5882\",\n",
    "    \"output_format\": \"geojson\"\n",
    "}\n",
    "\n",
    "print(\"Sende Anfrage an GeoSphere API...\")\n",
    "\n",
    "try:\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(\"ERFOLG: Daten empfangen!\")\n",
    "        \n",
    "        timestamps = data.get(\"timestamps\", [])\n",
    "        features = data.get(\"features\", [])\n",
    "\n",
    "        if features:\n",
    "            props = features[0][\"properties\"][\"parameters\"]\n",
    "            station_id = features[0][\"properties\"].get(\"station\", \"5882\")\n",
    "            \n",
    "            # 1. Daten in ein Dictionary sammeln\n",
    "            storage_dict = {\"timestamp\": timestamps}\n",
    "            \n",
    "            for p in params[\"parameters\"]:\n",
    "                if p in props:\n",
    "                    storage_dict[p] = props[p][\"data\"]\n",
    "            \n",
    "            # 2. In DataFrame umwandeln\n",
    "            df = pd.DataFrame(storage_dict)\n",
    "            \n",
    "            # Ersten Wert anzeigen (wie gewünscht)\n",
    "            if not df.empty and \"TL\" in df.columns:\n",
    "                print(f\"Erster gemessener Temperaturwert: {df['TL'].iloc[0]}°C\")\n",
    "            \n",
    "            # 3. Vorbereitung für MongoDB (Liste von Dokumenten)\n",
    "            # Wir fügen die Stations-ID zu jedem Datensatz hinzu\n",
    "            df['station_id'] = station_id\n",
    "            mongo_docs = df.to_dict(orient=\"records\")\n",
    "            \n",
    "            print(f\"Frame erstellt. {len(mongo_docs)} Datensätze bereit für MongoDB.\")\n",
    "            \n",
    "            # Beispiel-Ausgabe eines Datensatzes für MongoDB\n",
    "            print(\"\\nBeispiel-Datensatz für MongoDB:\")\n",
    "            print(json.dumps(mongo_docs[0], indent=2))\n",
    "            \n",
    "            # HIER könntest du jetzt schreiben:\n",
    "            # collection.insert_many(mongo_docs)\n",
    "            \n",
    "        else:\n",
    "            print(\"Verbindung ok, aber keine Features gefunden.\")\n",
    "    else:\n",
    "        print(f\"Fehler {response.status_code}: {response.text}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ein Fehler ist aufgetreten: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a5131c4c-df8f-4d37-98b0-b7b0ebde4be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erstelle Unique Index für 'timestamp'...\n",
      "--- ABSCHLUSSBERICHT ---\n",
      "Datenbank: BDA | Collection: Station_5882\n",
      "Neu gespeichert: 35280\n",
      "Übersprungene Duplikate: 0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient, errors\n",
    "import io\n",
    "\n",
    "# --- KONFIGURATION ---\n",
    "DB_NAME = \"BDA\"        # So heißt deine Datenbank\n",
    "COLLECTION_NAME = \"Station_5882\" # So heißt deine Tabelle (Collection)\n",
    "\n",
    "# API Setup\n",
    "base_url = \"https://dataset.api.hub.geosphere.at/v1/station/historical/klima-v1-10min\"\n",
    "params = {\n",
    "    \"parameters\": [\"RR\", \"TL\", \"P\", \"FF\", \"SO\", \"RF\"],\n",
    "    \"start\": \"2024-01-01T00:00\",\n",
    "    \"end\": \"2024-12-31T00:00\",\n",
    "    \"station_ids\": \"5882\",\n",
    "    \"output_format\": \"geojson\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    # 1. Daten von GeoSphere laden\n",
    "    response = requests.get(base_url, params=params)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    \n",
    "    # DataFrame erstellen\n",
    "    timestamps = data.get(\"timestamps\", [])\n",
    "    props = data[\"features\"][0][\"properties\"][\"parameters\"]\n",
    "    storage_dict = {\"timestamp\": timestamps}\n",
    "    for p in params[\"parameters\"]:\n",
    "        if p in props:\n",
    "            storage_dict[p] = props[p][\"data\"]\n",
    "    \n",
    "    df = pd.DataFrame(storage_dict)\n",
    "    df['station_id'] = \"5882\"\n",
    "    mongo_docs = df.to_dict(orient=\"records\")\n",
    "\n",
    "    # --- 2. MONGODB VERBINDUNG & INDEX ---\n",
    "    # Nutze den Namen, der in deinem Docker-Screenshot steht\n",
    "    client = MongoClient('mongodb://big_data_mongo:27017/')\n",
    "    db = client[DB_NAME]\n",
    "    collection = db[COLLECTION_NAME]\n",
    "\n",
    "    # UNIQUE INDEX ERSTELLEN\n",
    "    # 'timestamp' muss einzigartig sein. 1 bedeutet aufsteigend sortiert.\n",
    "    print(\"Erstelle Unique Index für 'timestamp'...\")\n",
    "    collection.create_index([(\"timestamp\", 1)], unique=True)\n",
    "\n",
    "    # --- 3. DATEN SPEICHERN MIT DUPLIKAT-CHECK ---\n",
    "    if mongo_docs:\n",
    "        success_count = 0\n",
    "        duplicate_count = 0\n",
    "        \n",
    "        for doc in mongo_docs:\n",
    "            try:\n",
    "                collection.insert_one(doc)\n",
    "                success_count += 1\n",
    "            except errors.DuplicateKeyError:\n",
    "                # Dieser Fehler tritt auf, wenn der Timestamp schon existiert\n",
    "                duplicate_count += 1\n",
    "        \n",
    "        print(f\"--- ABSCHLUSSBERICHT ---\")\n",
    "        print(f\"Datenbank: {DB_NAME} | Collection: {COLLECTION_NAME}\")\n",
    "        print(f\"Neu gespeichert: {success_count}\")\n",
    "        print(f\"Übersprungene Duplikate: {duplicate_count}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Fehler: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96e1270-bb9f-442b-b27c-1e37a474d45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erstelle Unique Index für 'timestamp'...\n",
      "--- ABSCHLUSSBERICHT ---\n",
      "Datenbank: big_data_austria | Collection: Station_HW_25\n",
      "Neu gespeichert: 8641\n",
      "Übersprungene Duplikate: 0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient, errors\n",
    "import io\n",
    "\n",
    "# --- KONFIGURATION ---\n",
    "DB_NAME = \"big_data_austria\"        # So heißt deine Datenbank\n",
    "COLLECTION_NAME = \"Station_HW_25\" # So heißt deine Tabelle (Collection)\n",
    "\n",
    "# API Setup\n",
    "base_url = \"https://dataset.api.hub.geosphere.at/v1/station/historical/tawes-v1-10min\"\n",
    "params = {\n",
    "    \"parameters\": [\"RR\", \"TL\", \"P\", \"FF\", \"SO\", \"RF\"],\n",
    "    \"start\": \"2025-11-01T00:00\",\n",
    "    \"end\": \"2025-12-31T00:00\",\n",
    "    \"station_ids\": \"11035\",\n",
    "    \"output_format\": \"geojson\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    # 1. Daten von GeoSphere laden\n",
    "    response = requests.get(base_url, params=params)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    \n",
    "    # DataFrame erstellen\n",
    "    timestamps = data.get(\"timestamps\", [])\n",
    "    props = data[\"features\"][0][\"properties\"][\"parameters\"]\n",
    "    storage_dict = {\"timestamp\": timestamps}\n",
    "    for p in params[\"parameters\"]:\n",
    "        if p in props:\n",
    "            storage_dict[p] = props[p][\"data\"]\n",
    "    \n",
    "    df = pd.DataFrame(storage_dict)\n",
    "    df['station_id'] = \"HW_25\"\n",
    "    mongo_docs = df.to_dict(orient=\"records\")\n",
    "\n",
    "    # --- 2. MONGODB VERBINDUNG & INDEX ---\n",
    "    # Nutze den Namen, der in deinem Docker-Screenshot steht\n",
    "    client = MongoClient('mongodb://mongodb:27017')\n",
    "    db = client[DB_NAME]\n",
    "    collection = db[COLLECTION_NAME]\n",
    "\n",
    "    # UNIQUE INDEX ERSTELLEN\n",
    "    # 'timestamp' muss einzigartig sein. 1 bedeutet aufsteigend sortiert.\n",
    "    print(\"Erstelle Unique Index für 'timestamp'...\")\n",
    "    collection.create_index([(\"timestamp\", 1)], unique=True)\n",
    "\n",
    "    # --- 3. DATEN SPEICHERN MIT DUPLIKAT-CHECK ---\n",
    "    if mongo_docs:\n",
    "        success_count = 0\n",
    "        duplicate_count = 0\n",
    "        \n",
    "        for doc in mongo_docs:\n",
    "            try:\n",
    "                collection.insert_one(doc)\n",
    "                success_count += 1\n",
    "            except errors.DuplicateKeyError:\n",
    "                # Dieser Fehler tritt auf, wenn der Timestamp schon existiert\n",
    "                duplicate_count += 1\n",
    "        \n",
    "        print(f\"--- ABSCHLUSSBERICHT ---\")\n",
    "        print(f\"Datenbank: {DB_NAME} | Collection: {COLLECTION_NAME}\")\n",
    "        print(f\"Neu gespeichert: {success_count}\")\n",
    "        print(f\"Übersprungene Duplikate: {duplicate_count}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Fehler: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed3cced-0b86-489b-8394-5bd203775cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
